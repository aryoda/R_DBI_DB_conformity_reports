---
title: "DBI conformity test results"
author: "https://github.com/aryoda/R_DBI_DB_conformity_reports"
date: '`r format(Sys.Date(), format = "%B %d, %Y")`'
output: 
  html_document: 
    number_sections: yes
    toc: yes
---

<style type="text/css">
div#TOC li {
    list-style:none;
    background-image:none;
    background-repeat:none;
    background-position:0; 
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(knitr)
require(kableExtra)
require(formattable)
require(ggplot2)
```




```{r old_code, echo = FALSE, eval = FALSE}
# snippet disabled since it shows a stupid result
# but collects helpful links at least

# Parameterized reports:
# http://rmarkdown.rstudio.com/developer_parameterized_reports.html?version=1.1.383&mode=desktop
#
# knitr::kable(res.summary, format = "hmtl", caption = "DBI conformity test summary")
# print(res.summary)
#
# knitr recommends kable:
# https://bookdown.org/yihui/bookdown/tables.html
# Or use the extension kableExtra:
# https://haozhu233.github.io/kableExtra/awesome_table_in_html.html
#
# https://davidgohel.github.io/flextable/
#
# HTML table packages overview and feature comparisson:
# https://hughjonesd.github.io/huxtable/design-principles.html
# https://htmlpreview.github.io/?https://github.com/ropenscilabs/packagemetrics/blob/master/inst/doc/tableGallery.html
#
# formattable seems to be very strong:
# https://ropensci.org/blog/2017/06/27/packagemetrics/
knitr::kable(total.assert.summary, "html", caption = "DBI conformity test summary (based on assertion counts)")  %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  column_spec(3, background = derive.pct.HTML.color(total.assert.summary$success.rate.asserts), color = "white", bold = TRUE)

# knitr::kable(per.group.assert.result, "html", caption = "Summary per test group")  %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
#   column_spec(4, background = "blue", color = "white", bold = TRUE)

```



# Test set-up

```{r, echo = FALSE}
# Overview over the set set-up (infrastructure, software versions etc.)
setup <- data.table(
           Property = c("Testing date",
                        "DBItest package version",
                        "Database name", "Database version",
                        "DBI driver package name", "DBI driver package version",
                        "R version",
                        "Client OS name", "Client OS platform", "Client OS version"),
           Value    = c(format(res.raw$date[1], format = "%B %d, %Y"),
                        res.raw$DBItest.pkg.version[1],
                        res.raw$DB.name[1], res.raw$DB.version[1],
                        res.raw$DBI.driver.pkg[1], res.raw$DBI.driver.pkg.version[1],
                        res.raw$client.R.version[1],
                        res.raw$client.OS.name[1], res.raw$client.OS.platform[1], res.raw$client.OS.version[1])
)

setup %>% 
  kable("html", escape = FALSE, caption = "")  %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) 

```



# How to read the results

## Test case vs. assertions

The DBI conformity tests are done using the R package `DBItest` which uses the package `testthat` internally
to execute the test cases.

To understand the test results below you need to understand the meaning of two terms:

1. **Test case ("TC")**:      A call of the `testthat::test_that()` function
2. **Assertion ("asserts")**: A call of an `testthat::expect*()` function

The test summaries can be based on a "per test case count" or one level finer on a "per checked assertion count".

The **"per test case count"** gives a good overview which features are working as expected.

The **per checked assertion count** indicates,

* how many assertions a test case is checking (= how comprehensive a test case is)
* how many problems caused a test case to fail (= how severe the problems are)



## Semantics of the used colors

There are only three colors used to mark test result rates (percentages):

1. Green: Good or perfekt
2. Orange: OK, but could be better
3. Red: A severe problem



# Summary of test results

## Test case counts

### Total summary

```{r Total Summary, echo = FALSE, fig.align = 'left'}
TC.result.colors <- eval(formals(derive.strings.HTML.color)$string.colors)   # DIRTY reuse default value of function argument

# https://stackoverflow.com/questions/10834382/ggplot2-keep-unused-levels-barplot
# https://stackoverflow.com/questions/30739602/ggplot-reorder-stacked-bar-plot-based-on-values-in-data-frame
# https://stackoverflow.com/questions/37817809/r-ggplot-stacked-bar-chart-with-counts-on-y-axis-but-percentage-as-label
# https://stackoverflow.com/questions/37817809/r-ggplot-stacked-bar-chart-with-counts-on-y-axis-but-percentage-as-label
d <- ggplot(test.case.groups.pivot.base, aes(x = test.group, y = TC.pct), fill = TC.result) +
  geom_bar(stat = "identity", aes(fill = TC.result), position = position_stack(), width = 0.7) +
  # number of test cases as label
  # Important: Requires data rows in the same order as test.group factors to show the TC.pct in the correct bar!
  #   Done before by sorting the data rows...
  geom_text(aes(x = test.group, y = TC.pct, label = test.cases),
            position = position_stack(vjust = 0.5), color = "white", fontface = "bold", size = 3.5) +
  ylab("Weight in %") +
  # now axis label (redundant to facet name)
  xlab("") + # xlab("Test Case Group") +
  # assign intuitive colors to stacked bars
  scale_fill_manual(values = TC.result.colors, name = "TC result") +
  coord_flip() +
  ggtitle("Total and per test case group (test case weights and counts)") +
  # Show total summary and details per test case group in two plots below each other
  facet_grid( granularity ~ ., scales = "free_y", space = "free_y")
d # show the plot
```


```{r, echo = FALSE}
# Total summary of the conformity test
res.sum3 <- copy(total.test.case.summary)

res.sum3[, ':='(
                 TC.result      = cell_spec(TC.result, "html", color = "white", bold = TRUE,
                                              background = derive.strings.HTML.color(TC.result)),
                 total.TC.share = cell_spec(total.TC.share, "html", color = "white", bold = TRUE,
                                            background = derive.strings.HTML.color(TC.result)))
        ] %>%
kable("html", escape = FALSE, caption = "Summary based on test case counts")  %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
add_footnote(c("percentage of the test cases from the total number of test cases",
               "BLUE color indicates counts of partially or completely skipped test cases"), notation = "number") # related column header is still missing

```



### Summary per test case group

```{r, echo = FALSE}
res4 <- copy(per.group.test.case.summary)

res4[, TC.success.rate := cell_spec(TC.success.rate, "html", color = "white", bold = TRUE,
                                             background = derive.pct.HTML.color(TC.success.rate))] %>%
           kable("html", escape = FALSE, caption = "Summary based on test case counts")  %>%
           kable_styling(bootstrap_options = c("striped", "hover", "condensed")) 

```



## Assertions counts

The summaries in this chapter are based on the assertion granularity which is one level
finer than the test case summary and gives an impression on how may problems contributed
to the failure (or success) of a test case.



### Summary per test case group


```{r, echo = FALSE}
# Result summary per test test case group

# Another version with different colors (conditional cell background)
# TODO Test coloring the whole table cell with <TD BGCOLOR="...">
res.sum2 = copy(per.group.assert.result)
# formattable(results$per.group.assert.result, list(success.rate = color_bar("#2dc937")))
# res.sum2[, success.rate2 := formattable(res.sum2, list(success.rate = color_bar("#2dc937")))] %>%

# res.sum2 %>% list(success.rate = color_bar("#2dc937")) %>%

res.sum2[, asserts.success.rate := cell_spec(asserts.success.rate, "html", color = "white", bold = TRUE,
                                             background = derive.pct.HTML.color(asserts.success.rate))] %>%
           kable("html", escape = FALSE, caption = "Summary based on assertions counts")  %>%
           kable_styling(bootstrap_options = c("striped", "hover", "condensed")) 

```



# Findings

## List of failed test cases

This section shall help you to

1. get a first overview about problematic features of the used combination of database, database driver and R package
   (e. g. to choose an alternative combination of you are in need of feature)
2. show you the names of the `testthat` test cases in the `DBItest` package that failed
   (e. g. to debug it as developer)

```{r, echo = FALSE}
details <- copy(res.raw[TC.result == "Failed", c(1, 3:11)]) [order(-error, TC.success.rate)]

fnm <- footnote_marker_number(1, "html")
new.col.names <- paste0(c("checked.asserts", "failed"), fnm)
setnames(details, c("nb", "failed"), new.col.names)

details[, ':='(TC.success.rate = cell_spec(TC.success.rate, "html", color = "white", bold = TRUE,
                                           background = derive.pct.HTML.color(TC.success.rate)),
                error = cell_spec(error, "html", color = "white", bold = TRUE,
                                  background = ifelse(error == TRUE, "red", "#2dc937"))
                )] %>%
kable("html", escape = FALSE, caption = "One row per test case (ordered by criticality)")  %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% 
add_footnote(c("based on counted assertions"), notation = "number")

```



## List of (partially or completly) skipped test cases

This table shows the **blind spots** in the DBI conformity tests since not all assertions in the test cases
have been checked.

**Note:**

The `testthat` "skip* functions are intended for use within test_that() blocks.

- All expectations following the skip* statement within the same test_that block will be skipped.
- **Test summaries that report skip counts are reporting how many test_that blocks triggered a skip* statement,
not how many expectations were skipped.**

Therefore no success rate is shown for skipped test cases even though some assertions (expectations may
have been checked)!


```{r, echo = FALSE}
details <- copy(res.raw[TC.result == "Skipped", c(1, 3:8, 11)]) [order(TC.success.rate)]

fnm <- footnote_marker_number(1, "html")
new.col.names <- paste0(c("checked.asserts", "failed"), fnm)
setnames(details, c("nb", "failed"), new.col.names)

details[, ':='(TC.success.rate = cell_spec(TC.success.rate, "html", color = "white", bold = TRUE,
                                           background = derive.pct.HTML.color(TC.success.rate))
                )] %>%
kable("html", escape = FALSE, caption = "One row per skipped test case (ordered by test gap rate)")  %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```


# Detailled results

This section shows the most granular test results: Per test case.


```{r, echo = FALSE}
full.details <- copy(res.raw[, c(1, 3:11)])

fnm <- footnote_marker_number(1, "html")
new.col.names <- paste0(c("checked.asserts", "failed"), fnm)
setnames(full.details, c("nb", "failed"), new.col.names)


full.details[, ':='(TC.success.rate = cell_spec(TC.success.rate, "html", color = "white", bold = TRUE,
                                                background = derive.pct.HTML.color(TC.success.rate)),
                    TC.result       = cell_spec(TC.result, "html", color = "white", bold = TRUE,
                                                background = derive.strings.HTML.color(TC.result)),
                    error           = cell_spec(error, "html", color = "white", bold = TRUE,
                                                background = ifelse(error == TRUE, "red", "#2dc937"))
                )] %>%
kable("html", escape = FALSE, caption = "One row per test case")  %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```
